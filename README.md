# üöÄ LangGraph Project Showcase


| Model / Provider             | Open-Source? | Size            | Licensing / Pricing               | Native Func-Call | LangChain Integration                   | LangGraph Integration                   | Multi-Agent Suitability             | Cost (High-End/Reasoning) $/1K-tk | Cost (Std/Ordinary) $/1K-tk | Pros                                                                          | Cons                                                                             |
|------------------------------|--------------|-----------------|-----------------------------------|------------------|-----------------------------------------|------------------------------------------|------------------------------------|-------------------------------|-----------------------------|-------------------------------------------------------------------------------|---------------------------------------------------------------------------------|
| **DeepSeek-R1**              | Yes          | 8 B (Qwen3)     | MIT (self-hosted; zero cost)      | No               | ‚úÖ via `langchain-ollama`               | ‚úÖ via custom wrappers                  | Moderate                            | 0.00                          | 0.00                        | ‚Ä¢ Offline, zero-cost<br>‚Ä¢ Lightweight, fits mid-range GPUs                    | ‚Ä¢ No native func-call<br>‚Ä¢ Needs JSON-wrapper & prompt engineering               |
| **Mistral 7B/8√ó**            | Yes          | 7 B / 8 B       | Apache 2.0 (self-hosted)          | No               | ‚úÖ via `langchain-mistral` or generic   | ‚úÖ via wrapper                          | Moderate                            | 0.00                          | 0.00                        | ‚Ä¢ Strong perf per param<br>‚Ä¢ Good instruction-following                      | ‚Ä¢ No built-in func-call<br>‚Ä¢ Quantization required for small GPUs               |
| **Qwen-Turbo/Max**           | Partially*   | 7 B‚Äì34 B        | API: free tier + usage fees       | **Yes** (API)    | ‚úÖ via `langchain-qwen`                 | ‚úÖ via Qwen-Agent                       | High                                | ~0.004                        | ~0.002                      | ‚Ä¢ Native func-calling via cloud API<br>‚Ä¢ Competitive benchmarks             | ‚Ä¢ Self-hosting loses native func-call<br>‚Ä¢ API costs can add up                 |
| **OpenRouter-Hosted**        | Partially*   | Varies          | API usage fees                    | **Yes** (API)    | ‚úÖ via `langchain`‚Äôs OpenRouter wrapper | ‚úÖ via wrapper                          | High                                | ~0.006                        | ~0.002                      | ‚Ä¢ Aggregates many models<br>‚Ä¢ Unified ‚ÄúChatGPT-style‚Äù API                    | ‚Ä¢ Dependent on third-party uptime & fees                                       |
| **Frontier Alpha/Beta**      | Yes          | 1.3 B‚Äì20 B      | Apache 2.0                        | No               | ‚úÖ via `langchain-frontier`             | ‚úÖ via wrapper                          | Moderate                            | 0.00                          | 0.00                        | ‚Ä¢ Ultra-fast CPU inference via ggml<br>‚Ä¢ Modular quantization                | ‚Ä¢ Early stage; fewer prebuilt tools<br>‚Ä¢ No native func-call                   |
| **OpenAI ChatGPT (GPT-4)**   | No           | ‚âà175 B          | Subscr. + per-token fees          | **Yes**          | ‚úÖ first-class via `langchain`          | ‚úÖ first-class via LangGraph‚Äôs OpenAI   | Very High                           | ~0.045                        | ~0.002                      | ‚Ä¢ Best-in-class reasoning<br>‚Ä¢ Native func-call & safety tools               | ‚Ä¢ Closed-source<br>‚Ä¢ Higher latency & cost                                     |
| **Google Gemini (Cloud)**    | No           | 1 B‚Äì100 B+     | Google Cloud billing              | **Yes**          | ‚úÖ via `langchain-googlegemini`         | ‚úÖ via wrapper                          | High                                | ~0.030                        | ~0.002                      | ‚Ä¢ Multimodal (text+vision)<br>‚Ä¢ Native func-call                             | ‚Ä¢ Closed-source<br>‚Ä¢ Complex pricing                                           |
| **Grok (X by Meta)**         | No           | ‚âà175 B?         | Free tier (X Premium)             | No               | ‚úÖ via generic OpenAI client            | ‚úÖ via wrapper                          | Moderate                            | 0.00                          | 0.00                        | ‚Ä¢ Integrated into X platform<br>‚Ä¢ Free for social use                        | ‚Ä¢ Limited API docs<br>‚Ä¢ No native func-call                                    |
| **Azure OpenAI Service**     | No           | GPT-3.5‚ÄìGPT-4   | Azure subscr. + usage              | **Yes**          | ‚úÖ via `langchain`‚Äôs Azure integration  | ‚úÖ via LangGraph‚Äôs OpenAI               | Very High                           | ~0.045                        | ~0.002                      | ‚Ä¢ Enterprise SLAs<br>‚Ä¢ MS ecosystem integration                               | ‚Ä¢ Locked to Azure<br>‚Ä¢ Same closed-source limits                               |
| **Anthropic Claude 2/3**      | No           | 70 B‚Äì100 B+     | Pay-as-you-go API                  | **Yes**          | ‚úÖ via `langchain-anthropic`            | ‚úÖ via wrapper                          | High                                | ~0.030                        | ~0.009                      | ‚Ä¢ Strong safety guardrails<br>‚Ä¢ Good func-call                               | ‚Ä¢ Closed-source<br>‚Ä¢ Higher cost per call than cheaper alternatives            |

\* ‚ÄúPartially‚Äù: checkpoint is open-source, but only the hosted/cloud API offers native function-calling; self-hosting requires a wrapper.  


A curated list of example projects built with **LangGraph**, demonstrating common patterns for LLM-driven workflows.

- **üîç RAG Agent (Retrieval-Augmented Generation)**  
  A pipeline that ingests external data (e.g. news, prices), stores embeddings in a vectorstore, rewrites user queries, and returns context-aware answers via a LangGraph state machine.

- **ü§ñ ReACT Agent**  
  A ‚ÄúReason & Act‚Äù loop that alternates internal reasoning steps with tool invocations. Ideal for tasks that require on-the-fly API calls, custom functions, or search tools.

- **ü§ñ Deekseek**  

- **üí≠ Reflection Agent**  
  A two-node graph that alternates between generating content and self-critiquing it. Useful for iterative improvement of creative outputs like tweets, blog posts, or marketing copy.

- **üîÑ Reflexion Agent**  
  An extended ‚ÄúDraft ‚Üí Execute Tools ‚Üí Revise‚Äù agent using structured Pydantic schemas. It drafts an answer, recommends search queries, fetches data, then revises with citations‚Äîlooping until convergence.

- **üõ†Ô∏è ToolExecutor Showcase**  
  A standalone demonstration of integrating external tools (e.g. web search, calculators) into LangGraph. Highlights the use of `ToolInvocation` and `ToolMessage` for seamless tool orchestration.

- **üìà Monitoring & Costing**  
  An example integration with LangSmith to log token usage, latency, and cost for each LangGraph execution, enabling real-time observability and optimization.

- **üìä Mermaid & Graphviz Visuals**  
  Utilities for rendering your LangGraph workflows as Mermaid diagrams or ASCII art‚Äîperfect for documentation, presentations, or interactive notebooks.

---

> Each template comes with ready-to-run code, prompt configurations, and environment setups. Fork any example to bootstrap your own LangGraph-powered agent!
